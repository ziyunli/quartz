## V3

[deepseek-ai/DeepSeek-V3-Base](https://simonwillison.net/2024/Dec/25/deepseek-v3/)

[DeepSeek_V3.pdf](https://simonwillison.net/2024/Dec/26/deepseek-v3/)

## Misc

[揭秘DeepSeek:一个更极致的中国技术理想主义故事](https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg)

Posted on [[202407]], about DeepSeek-v2.

> 我们的原则是不贴钱，也不赚取暴利。这个价格也是在成本之上稍微有点利润。

> 如果目标是做应用，那沿用 Llama结构，短平快上产品也是合理选择。但我们目的地是AGI，这意味着我们需要研究新的模型结构，在有限资源下，实现更强的模型能力。这是scale up到更大模型所需要做的基础研究之一。除了模型结构，我们还做了大量其他的研究，包括怎么构造数据，如何让模型更像人类等，这都体现在我们发布的模型里。另外，Llama的结构，在训练效率和推理成本上，和国外先进水平估计也已有两代差距。

> 短期内没有融资计划，我们面临的问题从来不是钱，而是高端芯片被禁运。

> 技术没有秘密，但重置需要时间和成本。英伟达的显卡，理论上没有任何技术秘密，很容易复制，但重新组织团队以及追赶下一代技术都需要时间，所以实际的护城河还是很宽。

> 我经常思考的是，一个东西能不能让社会的运行效率变高，以及你能否在它的产业分工链条上找到擅长的位置。只要终局是让社会效率更高[^1]，就是成立的。中间很多都是阶段性的，过度关注必然眼花缭乱。

> 并没有什么高深莫测的奇才，都是一些Top高校的应届毕业生、没毕业的博四、博五实习生，还有一些毕业才几年的年轻人。
>
> V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。

> (On AGI)...可能是2年、5年或者10年，总之会在我们有生之年实现。至于路线图，即使在我们公司内部，也没有统一意见。但我们确实押注了三个方向。一是数学和代码，二是多模态，三是自然语言本身。数学和代码是AGI天然的试验场，有点像围棋，是一个封闭的、可验证的系统，有可能通过自我学习就能实现很高的智能。另一方面，可能多模态、参与到人类的真实世界里学习，对AGI也是必要的。我们对一切可能性都保持开放。

[^1]: Utilitarianism: 效益主义
