## V3

[deepseek-ai/DeepSeek-V3-Base](https://simonwillison.net/2024/Dec/25/deepseek-v3/)

[DeepSeek_V3.pdf](https://simonwillison.net/2024/Dec/26/deepseek-v3/)

> DeepSeek (Chinese AI co) making it look easy today with an open weights release of a frontier-grade LLM trained on a joke of a budget (2048 GPUs for 2 months, $6M). For reference, this level of capability is supposed to require clusters of closer to 16K GPUs, the ones being brought up today are more around 100K GPUs. E.g. Llama 3 405B used 30.8M GPU-hours, while DeepSeek-V3 looks to be a stronger model at only 2.8M GPU-hours (~11X less compute). [^2]

## Misc

### [疯狂的幻方：一家隐形AI巨头的大模型之路](https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA) #Business

(Posted on [[202405]])

> 当国内云厂商高性能GPU芯片缺货成为限制中国生成式AI诞生的最直接因素时，据《财经十一人》报道，**国内拥有超过1万枚GPU的企业不超过5家。而除几家头部大厂外，还包括一家名为幻方的量化基金公司。通常认为，1万枚英伟达A100芯片是做自训大模型的算力门槛。**
>
> 其实，这家很少被置于人工智能视野打量的公司，早已是一家隐秘的AI巨头：2019年，幻方量化成立AI公司，其自研的深度学习训练平台“萤火一号”总投资近2亿元，搭载了1100块GPU；两年后，“萤火二号”的投入增加到10亿元，搭载了约1万张英伟达A100显卡。

> 现在看起来，无论大厂，还是创业公司，都很难在短时间内建立起碾压对手的技术优势。因为有OpenAI指路，又都基于公开论文和代码，最晚明年，大厂和创业公司都会把自己的大语言模型做出来。
>
> 大厂和创业公司都各有机会。现有垂类场景不掌握在初创公司手上，这个阶段对初创公司不太友好。但因为这种场景说到底也是分散的、碎片化的小需求，所以它又是更适合灵活的创业型组织的。从长期看，大模型应用门槛会越来越低，初创公司在未来20年任何时候下场，也都有机会。
> 我们的目标也很明确，就是不做垂类和应用，而是做研究，做探索。

On VC in China:

> 接触下来，感觉很多VC对做研究有顾虑，他们有退出需求，希望尽快做出产品商业化，而按照我们优先做研究的思路，很难从VC那里获得融资。但我们有算力和一个工程师团队，相当于有了一半筹码。

On company culture:

> 如果追求短期目标，找现成有经验的人是对的。但如果看长远，经验就没那么重要，基础能力、创造性、热爱等更重要。从这个角度看，国内合适的候选人就不少。
>
> 不一定是做过这件事的人才能做这件事。幻方招人有条原则是，看能力，而不是看经验。我们的核心技术岗位，基本以应届和毕业一两年的人为主。
>
> 做一件事，有经验的人会不假思索告诉你，应该这样做，但没有经验的人，会反复摸索、很认真去想应该怎么做，然后找到一个符合当前实际情况的解决办法。
>
> 我们的核心团队，连我自己，一开始都没有量化经验，这一点很特殊。不能说是成功的秘密，但这是幻方的文化之一。我们不会故意回避有经验的人，但更多是看能力。
>
> 事实上，第一年他们什么都做不出来，第二年才开始有点成绩。但我们的考核标准和一般公司不太一样。我们没有 KPI，也没有所谓的任务。
>
> 我们的总结是，创新需要尽可能少的干预和管理，让每个人有自由发挥的空间和试错机会。创新往往都是自己产生的，不是刻意安排的，更不是教出来的。

On startups:

> 按照教科书的方法论来推导创业公司，在当下，他们做的事，都是活不下来的。
>
> 但市场是变化的。真正的决定力量往往不是一些现成的规则和条件，而是一种适应和调整变化的能力。
>
> 很多大公司的组织结构已经不能快速响应和快速做事，而且他们很容易让之前的经验和惯性成为束缚，而这波AI新浪潮之下，一定会有一批新公司诞生。

### [揭秘DeepSeek:一个更极致的中国技术理想主义故事](https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg) #Business

Posted on [[202407]], about DeepSeek-v2.

> 我们的原则是不贴钱，也不赚取暴利。这个价格也是在成本之上稍微有点利润。

> 如果目标是做应用，那沿用 Llama结构，短平快上产品也是合理选择。但我们目的地是AGI，这意味着我们需要研究新的模型结构，在有限资源下，实现更强的模型能力。这是scale up到更大模型所需要做的基础研究之一。除了模型结构，我们还做了大量其他的研究，包括怎么构造数据，如何让模型更像人类等，这都体现在我们发布的模型里。另外，Llama的结构，在训练效率和推理成本上，和国外先进水平估计也已有两代差距。

> 短期内没有融资计划，我们面临的问题从来不是钱，而是高端芯片被禁运。

> 技术没有秘密，但重置需要时间和成本。英伟达的显卡，理论上没有任何技术秘密，很容易复制，但重新组织团队以及追赶下一代技术都需要时间，所以实际的护城河还是很宽。

> 我经常思考的是，一个东西能不能让社会的运行效率变高，以及你能否在它的产业分工链条上找到擅长的位置。只要终局是让社会效率更高[^1]，就是成立的。中间很多都是阶段性的，过度关注必然眼花缭乱。

> 并没有什么高深莫测的奇才，都是一些Top高校的应届毕业生、没毕业的博四、博五实习生，还有一些毕业才几年的年轻人。
>
> V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。

> (On AGI)...可能是2年、5年或者10年，总之会在我们有生之年实现。至于路线图，即使在我们公司内部，也没有统一意见。但我们确实押注了三个方向。一是数学和代码，二是多模态，三是自然语言本身。数学和代码是AGI天然的试验场，有点像围棋，是一个封闭的、可验证的系统，有可能通过自我学习就能实现很高的智能。另一方面，可能多模态、参与到人类的真实世界里学习，对AGI也是必要的。我们对一切可能性都保持开放。

[^1]: Utilitarianism: 效益主义

[^2]: [Andrej Karpathy](https://x.com/karpathy/status/1872362712958906460)
