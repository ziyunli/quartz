<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="I signed up Large Language Models: Application through Production by Databricks on edX to learn more about applications of Large Language Model."><meta property="og:title" content="Large Language Models: Application through Production"><meta property="og:description" content="I signed up Large Language Models: Application through Production by Databricks on edX to learn more about applications of Large Language Model."><meta property="og:type" content="website"><meta property="og:image" content="https://ziyunli.github.io/quartz/icon.png"><meta property="og:url" content="https://ziyunli.github.io/quartz/notes/LLM101x/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Large Language Models: Application through Production"><meta name=twitter:description content="I signed up Large Language Models: Application through Production by Databricks on edX to learn more about applications of Large Language Model."><meta name=twitter:image content="https://ziyunli.github.io/quartz/icon.png"><title>Large Language Models: Application through Production</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://ziyunli.github.io/quartz//icon.png><link href=https://ziyunli.github.io/quartz/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://ziyunli.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://ziyunli.github.io/quartz/js/darkmode.390405ce4fa88508cf8c697cadc4cf14.min.js></script>
<script src=https://ziyunli.github.io/quartz/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://ziyunli.github.io/quartz/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://ziyunli.github.io/quartz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://ziyunli.github.io/quartz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://ziyunli.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://ziyunli.github.io/quartz/",fetchData=Promise.all([fetch("https://ziyunli.github.io/quartz/indices/linkIndex.bf1938c024b67978ce9a9af11820268b.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://ziyunli.github.io/quartz/indices/contentIndex.a954f08770b36dd9204177b213f3f5fd.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://ziyunli.github.io/quartz",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://ziyunli.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/ziyunli.github.io\/quartz\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=ziyunli.github.io/quartz src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://ziyunli.github.io/quartz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://ziyunli.github.io/quartz/>ðŸª´ Ziyun's Backyard</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Large Language Models: Application through Production</h1><p class=meta>Last updated
Jun 13, 2023
<a href=https://github.com/ziyunli/quartz/tree/hugo/content/notes/LLM101x.md rel=noopener>Edit Source</a></p><ul class=tags><li><a href=https://ziyunli.github.io/quartz/tags/Course/>Course</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#introduction>Introduction</a></li><li><a href=#application>Application</a></li><li><a href=#embedding-and-vector-store>Embedding and Vector Store</a><ol><li><a href=#how-do-lms-learn-knowledge>How do LMs learn knowledge</a></li><li><a href=#how-does-vector-search-work>How does Vector Search work</a></li><li><a href=#filtering>Filtering</a></li><li><a href=#vector-stores>Vector Stores</a></li></ol></li></ol></nav></details></aside><p>I signed up
<a href=https://learning.edx.org/course/course-v1:Databricks+LLM101x+2T2023/home rel=noopener>Large Language Models: Application through Production</a> by Databricks on edX to learn more about applications of
<a href=/quartz/notes/LLM/ rel=noopener class=internal-link data-src=/quartz/notes/LLM/>Large Language Model</a>. This page contains my notes on the course.</p><a href=#introduction><h2 id=introduction><span class=hanchor arialabel=Anchor># </span>Introduction</h2></a><p>This module goes through some key concepts and terminology.</p><ul><li>Language models: probabilistic models that assign probabilities to word sequences.</li><li>Large: from 10~50M to many billions of parameters. Made possible by transformer architecture since ~2017.</li></ul><p>Primitives:</p><ul><li>Token: basic building block of language models. Words, sub-words, characters, etc.</li><li>Sentence: sequence of tokens.</li><li>Vocabulary: complete list of tokens.</li></ul><p>Tokenization:</p><ol><li>Words:<ol><li>Intuitive</li><li>Big vocabulary</li><li>Complications such as misspelling, out-of-vocabulary (OOV) words, etc.</li></ol></li><li>Characters:<ol><li>Small vocabulary</li><li>No OOV</li><li>Long sequences</li><li>No word-level semantics</li></ol></li><li>Sub-words:</li><li>popular: byte pair encoding (BPE)</li></ol><p>Word embeddings:</p><ol><li>By frequency â†’ sparsity issue</li><li>word/token â†’ embedding function â†’ word embedding/vector</li></ol><a href=#application><h2 id=application><span class=hanchor arialabel=Anchor># </span>Application</h2></a><p>This module is mostly an introduction to the transformer library from Hugging Face. The code examples are very straightforward to understand if you already know Python.
In fact, the whole lab takes around 10 minutes to complete if it&rsquo;s not waiting to download all the data sets and models along the way.</p><p>On the high level, a HF pipeline could have these steps:
<code>input --> id[prompt constructions] --> id[tokenizer (encoding)] --> model --> id[tokenizer (decoding)] --> output</code></p><p>Some parameters to tweak:</p><ul><li>tokenizer:<ul><li><code>max_length</code>: max length of input sequence</li></ul></li><li>model:<ul><li><code>do_sample</code>: whether to use sampling<ul><li><code>top_k</code>: top k tokens to sample from</li><li><code>top_p</code>: cumulative probability of top tokens to sample from</li><li><code>termperture</code>: temperature of sampling</li></ul></li><li><code>num_beams</code>: number of beams for beam search</li><li><code>max_length</code>: max length of output sequence</li><li><code>min_length</code>: min length of output sequence</li></ul></li></ul><a href=#embedding-and-vector-store><h2 id=embedding-and-vector-store><span class=hanchor arialabel=Anchor># </span>Embedding and Vector Store</h2></a><a href=#how-do-lms-learn-knowledge><h3 id=how-do-lms-learn-knowledge><span class=hanchor arialabel=Anchor># </span>How do LMs learn knowledge</h3></a><ul><li>fine-tuning<ul><li>via model weights</li><li><em>usually</em> better suited to teach a model the specialized tasks<ul><li>Studying for an exam 2 weeks away</li></ul></li></ul></li><li>in-context learning<ul><li>through model inputs</li><li>passing context as model inputs improves factual recall<ul><li>&ldquo;Take an exam with open notes&rdquo;</li></ul></li><li>downsides<ul><li>Context length limitation</li><li>Longer context = higher API costs = longer processing times</li></ul></li></ul></li></ul><p>We can turn words/images/audio with vectors</p><ul><li>similarity search<ul><li>de-dup</li><li>semantic search</li></ul></li><li>recommendation</li><li>finding security threats</li></ul><p><img src=https://ziyunli.github.io/quartz//assets/rag-workflow.png width=auto alt="search and retrieval-augmented generation"></p><a href=#how-does-vector-search-work><h3 id=how-does-vector-search-work><span class=hanchor arialabel=Anchor># </span>How does Vector Search work</h3></a><p>Vector search</p><ul><li>K-nearest neighbors (KNN): exact search; brute-force method</li><li><mark>Approximate nearest neighbors (ANN)</mark>:<ul><li>trade accuracy for speed.</li><li>Common indexing algorithms that output a <mark>vector index</mark><ul><li>Proximity graphs: HNSW<ul><li>Build proximity graphs based on L2 distance</li></ul></li><li>Clustering: FAISS<ul><li>forms clusters of dense vectors and conducts product quantization</li><li>Not good with sparse vectors</li></ul></li></ul></li></ul></li></ul><a href=#how-to-measure-similarity><h4 id=how-to-measure-similarity><span class=hanchor arialabel=Anchor># </span>How to measure similarity</h4></a><ul><li>Distance metrics: L2 (Euclidean)</li><li>Similarity metrics: Cosine</li></ul><p>Note: used on normalized embeddings, they produce functionally equivalent ranking distances.</p><p>Product quantization: to compress vectors with fewer bytes</p><ol><li>Split the big vector into segments of sub-vectors</li><li>Each sub-vector is quantized independently, and mapped to the nearest centroid</li></ol><a href=#filtering><h3 id=filtering><span class=hanchor arialabel=Anchor># </span>Filtering</h3></a><ol><li>Post-query</li><li>In-query</li><li>Pre-query</li></ol><a href=#vector-stores><h3 id=vector-stores><span class=hanchor arialabel=Anchor># </span>Vector Stores</h3></a><p>When do you need it? When you need <mark>context augmentation</mark>.</p><p>Vector databases</p><ul><li>CRUD</li><li>Optimized for unstructured data (vectors)</li><li>Built-in AAN algorithms</li></ul><p>Vector libraries:</p><ul><li>create vector indices</li><li>sufficient for small, static data</li><li>stored in-memory</li></ul><p>Tips:</p><ol><li>Choose your embedding model wisely<ol><li>It should represent <strong>BOTH</strong> queries and documents.</li></ol></li><li>Ensure the <mark>embedding space</mark> is the same for both queries and documents.<ol><li>Use the same model for indexing and querying</li><li>If use different models, make sure they are trained on similar data ðŸ¤”</li></ol></li><li>Chunking strategy<ol><li>Considerations<ol><li>How relevant</li><li>Token limit</li><li>User behavior<ol><li>How long are the queries?</li><li>Try to match with the context</li></ol></li></ol></li></ol></li></ol></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz/-now/ data-ctx="Large Language Models Application through Production" data-src=/-now class=internal-link>now</a></li><li><a href=/quartz/notes/Teach-Myself-LLM/ data-ctx="Large Language Models Application through Production" data-src=/notes/Teach-Myself-LLM class=internal-link>Teach Myself LLM</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://ziyunli.github.io/quartz/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Ziyun Li using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://ziyunli.github.io/quartz/>Home</a></li><li><a href=https://fedi.ziyun.rocks/@ziyun>Mastodon</a></li><li><a href=https://github.com/ziyunli>GitHub</a></li></ul></footer></div></div></body></html>